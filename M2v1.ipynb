{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a52069",
   "metadata": {},
   "source": [
    "### Постановка задачи\n",
    "\n",
    "Просмотр фильмов на оригинальном языке - это популярный и действенный метод обучения иностранным языкам. Важно выбрать фильм, который подходит студенту по уровню сложности, т.е. студент понимал бы 50-70 % диалогов. Чтобы выполнить это условие, преподаватель должен посмотреть фильм и решить, какому уровню он соответствует. Однако это требует больших временных затрат.\n",
    "\n",
    "Наша задача - разработать ML решение для автоматического определения уровня сложности англоязычных фильмов. \n",
    "\n",
    "Программа-максимум:\n",
    "\n",
    "           - языковая модель, \n",
    "           - веб-интерфейс,\n",
    "           - микросервис.  \n",
    "           \n",
    "### Знакомство с исходными данными\n",
    "\n",
    "В качестве исходных данных нам предоставлены размеченные по уровню сложности фильмы и субтитры к ним, словари английского языка с набором слов по уровню.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19763c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysrt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5748b2c",
   "metadata": {},
   "source": [
    "Сначала взглянем на эти файлы, чтоб понять, как можно было бы с ними вообще работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704680e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_A2 = './English_level/English scores/Subtitles_all/A2/The Walking Dead-S01E01-Days Gone Bye.English.srt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae33812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = pysrt.open(path_A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5036b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7efc7bb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:03,169 --> 00:00:05,171\n",
      "( bugs chittering )\n",
      "\n",
      "51\n",
      "00:06:24,376 --> 00:06:27,045\n",
      "- And what do you say to that?\n",
      "- I know what I want to say.\n",
      "\n",
      "101\n",
      "00:09:19,207 --> 00:09:22,085 X1:0\n",
      "Dispatcher:\n",
      "Unit 1, unit 3, to eastbound Route 18,\n",
      "\n",
      "151\n",
      "00:12:53,996 --> 00:12:56,332\n",
      "Shh shh. That's it. Do you hear me?\n",
      "Shh shh shh. Okay.\n",
      "\n",
      "201\n",
      "00:20:23,438 --> 00:20:25,440\n",
      "( bugs chittering )\n",
      "\n",
      "251\n",
      "00:28:20,153 --> 00:28:23,030\n",
      "Take a moment,\n",
      "look how sharp it is.\n",
      "\n",
      "301\n",
      "00:31:39,304 --> 00:31:40,388\n",
      "Yeah.\n",
      "\n",
      "351\n",
      "00:34:22,709 --> 00:34:26,086\n",
      "Man: Don't look.\n",
      "Get away from the windows.\n",
      "\n",
      "401\n",
      "00:38:37,536 --> 00:38:39,705\n",
      "That's right.\n",
      "\n",
      "451\n",
      "00:41:46,000 --> 00:41:47,835\n",
      "Conserve your ammo.\n",
      "\n",
      "501\n",
      "00:47:57,069 --> 00:47:59,071\n",
      "( growling )\n",
      "\n",
      "551\n",
      "00:52:00,594 --> 00:52:02,429\n",
      "You're all right.\n",
      "Go on. You're all right.\n",
      "\n",
      "601\n",
      "00:57:15,775 --> 00:57:17,485\n",
      "Good boy.\n",
      "\n",
      "651\n",
      "01:05:33,926 --> 01:05:36,595\n",
      "♪ Of the place I know so well ♪\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(subs), 50):\n",
    "    print(subs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e17b3",
   "metadata": {},
   "source": [
    "Чтобы проанализировать слова, нужно из этой структуры убрать тайминг, нумерацию кадров (видимо, это строки, потому что их количество равно длине файла с субтитрами), убрать слова в скобках, потому что в задаче запрос на понимание диалогов, а в скобках не диалоги, убрать знаки препинания и цифры, привести к нижнему регистру."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8ca7c3",
   "metadata": {},
   "source": [
    "### Создание единого датасета из предложенных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3467b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basepath = './English_level/English scores/Subtitles_all/'\n",
    "\n",
    "df_1 = pd.DataFrame(columns = ['Level', 'Movie', 'Srt'])\n",
    "\n",
    "\n",
    "for s in ('A2', 'B1', 'B2', 'C1'):\n",
    "    \n",
    "    path = os.path.join(basepath, s)\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        \n",
    "        with open(os.path.join(path, file), 'r', encoding='ISO-8859-1') as infile:\n",
    "            txt = infile.read()\n",
    "            \n",
    "        df_1.loc[len(df_1)] = [s, file[:-4], txt]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5c5287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Srt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2</td>\n",
       "      <td>The Walking Dead-S01E01-Days Gone Bye.English</td>\n",
       "      <td>1\\n00:00:03,169 --&gt; 00:00:05,171\\n( bugs chitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2</td>\n",
       "      <td>The Walking Dead-S01E02-Guts.English</td>\n",
       "      <td>1\\n00:00:03,045 --&gt; 00:00:05,047\\n- ( birds ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>The Walking Dead-S01E03-Tell It To The Frogs.E...</td>\n",
       "      <td>1\\n00:00:03,003 --&gt; 00:00:04,671\\n( thunder ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2</td>\n",
       "      <td>The Walking Dead-S01E04-Vatos.English</td>\n",
       "      <td>1\\n00:00:03,045 --&gt; 00:00:05,422\\n( birds chir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2</td>\n",
       "      <td>The Walking Dead-S01E05-Wildfire.English</td>\n",
       "      <td>1\\n00:00:03,420 --&gt; 00:00:04,922\\n- ( walkie-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>C1</td>\n",
       "      <td>Suits.S03E06.720p.HDTV.x264-mSD</td>\n",
       "      <td>ï»¿1\\n00:00:01,383 --&gt; 00:00:02,751\\nI lost Av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>C1</td>\n",
       "      <td>Suits.S03E07.HDTV.x264-mSD</td>\n",
       "      <td>ï»¿1\\n00:00:00,052 --&gt; 00:00:01,352\\nPreviousl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>C1</td>\n",
       "      <td>Suits.S03E08.480p.HDTV.x264-mSD</td>\n",
       "      <td>ï»¿1\\n00:00:01,436 --&gt; 00:00:03,028\\nI get Ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>C1</td>\n",
       "      <td>Suits.S03E09.480p.HDTV.x264-mSD</td>\n",
       "      <td>ï»¿1\\n00:00:00,024 --&gt; 00:00:01,478\\nPreviousl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>C1</td>\n",
       "      <td>Suits.S03E10.HDTV.x264-mSD</td>\n",
       "      <td>ï»¿1\\n00:00:00,015 --&gt; 00:00:01,196\\nPreviousl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Level                                              Movie  \\\n",
       "0      A2      The Walking Dead-S01E01-Days Gone Bye.English   \n",
       "1      A2               The Walking Dead-S01E02-Guts.English   \n",
       "2      A2  The Walking Dead-S01E03-Tell It To The Frogs.E...   \n",
       "3      A2              The Walking Dead-S01E04-Vatos.English   \n",
       "4      A2           The Walking Dead-S01E05-Wildfire.English   \n",
       "..    ...                                                ...   \n",
       "158    C1                    Suits.S03E06.720p.HDTV.x264-mSD   \n",
       "159    C1                         Suits.S03E07.HDTV.x264-mSD   \n",
       "160    C1                    Suits.S03E08.480p.HDTV.x264-mSD   \n",
       "161    C1                    Suits.S03E09.480p.HDTV.x264-mSD   \n",
       "162    C1                         Suits.S03E10.HDTV.x264-mSD   \n",
       "\n",
       "                                                   Srt  \n",
       "0    1\\n00:00:03,169 --> 00:00:05,171\\n( bugs chitt...  \n",
       "1    1\\n00:00:03,045 --> 00:00:05,047\\n- ( birds ch...  \n",
       "2    1\\n00:00:03,003 --> 00:00:04,671\\n( thunder ru...  \n",
       "3    1\\n00:00:03,045 --> 00:00:05,422\\n( birds chir...  \n",
       "4    1\\n00:00:03,420 --> 00:00:04,922\\n- ( walkie-t...  \n",
       "..                                                 ...  \n",
       "158  ï»¿1\\n00:00:01,383 --> 00:00:02,751\\nI lost Av...  \n",
       "159  ï»¿1\\n00:00:00,052 --> 00:00:01,352\\nPreviousl...  \n",
       "160  ï»¿1\\n00:00:01,436 --> 00:00:03,028\\nI get Ava...  \n",
       "161  ï»¿1\\n00:00:00,024 --> 00:00:01,478\\nPreviousl...  \n",
       "162  ï»¿1\\n00:00:00,015 --> 00:00:01,196\\nPreviousl...  \n",
       "\n",
       "[163 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ac99f",
   "metadata": {},
   "source": [
    "В первой таблице, собранной из данных папки заказчика с распределением субтитров по уровню языка,  у нас есть полный набор данных - название фильма, его рейтинг, текст субтитров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43635687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_2 = pd.DataFrame(columns = ['Movie', 'Srt'])\n",
    "path = os.path.join(basepath, 'Subtitles')\n",
    "for file in os.listdir(path):\n",
    "    if file!='.DS_Store':\n",
    "        \n",
    "        with open(os.path.join(path, file), 'r', encoding='ISO-8859-1') as infile:\n",
    "            txt = infile.read()\n",
    "        df_2.loc[len(df_2)] = [file[:-4], txt]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374a7c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Srt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>1\\n00:00:55,279 --&gt; 00:01:07,279\\n&lt;font color=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>1\\n00:01:54,281 --&gt; 00:01:55,698\\nHey!\\n\\n2\\n0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>1\\n00:00:27,240 --&gt; 00:00:30,879\\n&lt;i&gt;Oh, I com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All_dogs_go_to_heaven(1989)</td>\n",
       "      <td>1\\n00:00:12,319 --&gt; 00:00:14,821\\nCAPTIONING M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An_American_tail(1986)</td>\n",
       "      <td>ï»¿1\\n00:02:24,080 --&gt; 00:02:26,528\\n(INDISTIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Warm_bodies(2013)</td>\n",
       "      <td>2\\n00:00:26,559 --&gt; 00:00:28,627\\n&lt;i&gt;What am I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Westworld_scenes_of_Dr_Robert_Ford</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:21,179\\n[Music]\\n\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>We_are_the_Millers(2013)</td>\n",
       "      <td>1\\n00:00:02,400 --&gt; 00:00:03,731\\n&lt;i&gt;Oh, my Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>While_You_Were_Sleeping(1995)</td>\n",
       "      <td>1\\n00:02:20,760 --&gt; 00:02:24,720\\nLUCY: &lt;i&gt;Oka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Zootopia(2016)</td>\n",
       "      <td>ï»¿1\\n00:01:00,840 --&gt; 00:01:06,370\\nFear. Tre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Movie  \\\n",
       "0             10_Cloverfield_lane(2016)   \n",
       "1      10_things_I_hate_about_you(1999)   \n",
       "2                         Aladdin(1992)   \n",
       "3           All_dogs_go_to_heaven(1989)   \n",
       "4                An_American_tail(1986)   \n",
       "..                                  ...   \n",
       "110                   Warm_bodies(2013)   \n",
       "111  Westworld_scenes_of_Dr_Robert_Ford   \n",
       "112            We_are_the_Millers(2013)   \n",
       "113       While_You_Were_Sleeping(1995)   \n",
       "114                      Zootopia(2016)   \n",
       "\n",
       "                                                   Srt  \n",
       "0    1\\n00:00:55,279 --> 00:01:07,279\\n<font color=...  \n",
       "1    1\\n00:01:54,281 --> 00:01:55,698\\nHey!\\n\\n2\\n0...  \n",
       "2    1\\n00:00:27,240 --> 00:00:30,879\\n<i>Oh, I com...  \n",
       "3    1\\n00:00:12,319 --> 00:00:14,821\\nCAPTIONING M...  \n",
       "4    ï»¿1\\n00:02:24,080 --> 00:02:26,528\\n(INDISTIN...  \n",
       "..                                                 ...  \n",
       "110  2\\n00:00:26,559 --> 00:00:28,627\\n<i>What am I...  \n",
       "111  1\\n00:00:00,000 --> 00:00:21,179\\n[Music]\\n\\n2...  \n",
       "112  1\\n00:00:02,400 --> 00:00:03,731\\n<i>Oh, my Go...  \n",
       "113  1\\n00:02:20,760 --> 00:02:24,720\\nLUCY: <i>Oka...  \n",
       "114  ï»¿1\\n00:01:00,840 --> 00:01:06,370\\nFear. Tre...  \n",
       "\n",
       "[115 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da77310",
   "metadata": {},
   "source": [
    "Во второй таблице, тоже собранной из данных файлов в папке заказчика, но другой, не размеченной по уровню языка, есть названия фильмов и текст субтитров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079ea6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_excel('./English_level/English scores/movies_labels.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b2286a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2/A2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>Matilda(2022)</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>Bullet train</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>Thor: love and thunder</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>Lightyear</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>The Grinch</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                             Movie   Level\n",
       "0      0         10_Cloverfield_lane(2016)      B1\n",
       "1      1  10_things_I_hate_about_you(1999)      B1\n",
       "2      2              A_knights_tale(2001)      B2\n",
       "3      3              A_star_is_born(2018)      B2\n",
       "4      4                     Aladdin(1992)  A2/A2+\n",
       "..   ...                               ...     ...\n",
       "236  236                     Matilda(2022)      C1\n",
       "237  237                      Bullet train      B1\n",
       "238  238            Thor: love and thunder      B2\n",
       "239  239                         Lightyear      B2\n",
       "240  240                        The Grinch      B1\n",
       "\n",
       "[241 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a891786f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2/A2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Matilda(2022)</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Bullet train</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Thor: love and thunder</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Lightyear</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>The Grinch</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Movie   Level\n",
       "0           10_Cloverfield_lane(2016)      B1\n",
       "1    10_things_I_hate_about_you(1999)      B1\n",
       "2                A_knights_tale(2001)      B2\n",
       "3                A_star_is_born(2018)      B2\n",
       "4                       Aladdin(1992)  A2/A2+\n",
       "..                                ...     ...\n",
       "236                     Matilda(2022)      C1\n",
       "237                      Bullet train      B1\n",
       "238            Thor: love and thunder      B2\n",
       "239                         Lightyear      B2\n",
       "240                        The Grinch      B1\n",
       "\n",
       "[241 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.drop(columns='id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa31f70",
   "metadata": {},
   "source": [
    "В третьей таблице, предоставленной самим заказчиком, есть названия фильмов и уровень языка.\n",
    "\n",
    "Теперь нам предстоит объединить эти данные в одну таблицу.\n",
    "\n",
    "Столбцом для объединения точно будет название фильма. Объединение df_3 с df_2 не составит труда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b035cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_3 = df_3.merge(df_2, on='Movie', how='outer').drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30d0b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "      <th>Srt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>The_Legend_of_Tarzan(2016)</td>\n",
       "      <td>C1</td>\n",
       "      <td>1\\n00:02:17,040 --&gt; 00:02:18,724\\n&lt;i&gt;Monsieur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>House_of_Gucci(2021)</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:36,769 --&gt; 00:00:41,769\\n&lt;font color=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Ratatouille(2007)</td>\n",
       "      <td>B2</td>\n",
       "      <td>0\\n00:00:01,000 --&gt; 00:00:04,000\\nDownloaded F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Knives_out(2019)</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:01:43,157 --&gt; 00:01:45,459\\nMorning, Mr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Suits.S03E04.480pHDTV.x264-mSD</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Suits.S03E01.480pHDTV.x264-mSD</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Spirit.Stallion.of.the.Cimarron.EN</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Good_Will_Hunting(1997)</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:03:34,295 --&gt; 00:03:38,050\\nMod f-x-squa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Suits S04E15 EngSub</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>The_holiday(2006)</td>\n",
       "      <td>B1</td>\n",
       "      <td>1\\n00:01:06,900 --&gt; 00:01:10,700\\nI have found...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Movie Level  \\\n",
       "81           The_Legend_of_Tarzan(2016)    C1   \n",
       "43                 House_of_Gucci(2021)    B2   \n",
       "70                    Ratatouille(2007)    B2   \n",
       "48                     Knives_out(2019)    B2   \n",
       "228      Suits.S03E04.480pHDTV.x264-mSD    C1   \n",
       "225      Suits.S03E01.480pHDTV.x264-mSD    C1   \n",
       "131  Spirit.Stallion.of.the.Cimarron.EN    B1   \n",
       "36              Good_Will_Hunting(1997)    B2   \n",
       "223                 Suits S04E15 EngSub    C1   \n",
       "91                    The_holiday(2006)    B1   \n",
       "\n",
       "                                                   Srt  \n",
       "81   1\\n00:02:17,040 --> 00:02:18,724\\n<i>Monsieur ...  \n",
       "43   1\\n00:00:36,769 --> 00:00:41,769\\n<font color=...  \n",
       "70   0\\n00:00:01,000 --> 00:00:04,000\\nDownloaded F...  \n",
       "48   1\\n00:01:43,157 --> 00:01:45,459\\nMorning, Mr....  \n",
       "228                                                NaN  \n",
       "225                                                NaN  \n",
       "131                                                NaN  \n",
       "36   1\\n00:03:34,295 --> 00:03:38,050\\nMod f-x-squa...  \n",
       "223                                                NaN  \n",
       "91   1\\n00:01:06,900 --> 00:01:10,700\\nI have found...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2_3.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c679ea",
   "metadata": {},
   "source": [
    "И с третьей таблицей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e1b6d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_2_3.merge(df_1, on='Movie', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e7c4495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level_x</th>\n",
       "      <th>Srt_x</th>\n",
       "      <th>Level_y</th>\n",
       "      <th>Srt_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Before_sunrise(1995)</td>\n",
       "      <td>B1, B2</td>\n",
       "      <td>1\\n00:03:34,084 --&gt; 00:03:54,084\\n&lt;b&gt;Resync By...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Seven.Worlds.One.Planet.S01E06.2160p.BluRay.Re...</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>ï»¿1\\n00:00:44,462 --&gt; 00:00:47,506\\nOne conti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>The_cabin_in_the_woods(2012)</td>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>1\\n00:01:00,416 --&gt; 00:01:01,983\\nIt's hormona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Spirit.Stallion.of.the.Cimarron.EN</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>1\\n00:00:36,883 --&gt; 00:00:46,554\\n''Spirit Sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Movie Level_x  \\\n",
       "13                                Before_sunrise(1995)  B1, B2   \n",
       "129  Seven.Worlds.One.Planet.S01E06.2160p.BluRay.Re...      B1   \n",
       "87                        The_cabin_in_the_woods(2012)  A2/A2+   \n",
       "131                 Spirit.Stallion.of.the.Cimarron.EN      B1   \n",
       "\n",
       "                                                 Srt_x Level_y  \\\n",
       "13   1\\n00:03:34,084 --> 00:03:54,084\\n<b>Resync By...     NaN   \n",
       "129                                                NaN      B1   \n",
       "87   1\\n00:01:00,416 --> 00:01:01,983\\nIt's hormona...     NaN   \n",
       "131                                                NaN      B1   \n",
       "\n",
       "                                                 Srt_y  \n",
       "13                                                 NaN  \n",
       "129  ï»¿1\\n00:00:44,462 --> 00:00:47,506\\nOne conti...  \n",
       "87                                                 NaN  \n",
       "131  1\\n00:00:36,883 --> 00:00:46,554\\n''Spirit Sta...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3138cd",
   "metadata": {},
   "source": [
    "Есть пробелы в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6c3f107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie        0\n",
       "Level_x     49\n",
       "Srt_x      171\n",
       "Level_y    127\n",
       "Srt_y      127\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60bb576b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290 entries, 0 to 289\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Movie    290 non-null    object\n",
      " 1   Level_x  241 non-null    object\n",
      " 2   Srt_x    119 non-null    object\n",
      " 3   Level_y  163 non-null    object\n",
      " 4   Srt_y    163 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 11.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617b745",
   "metadata": {},
   "source": [
    "Столбцы уровней и субтитров будем объединять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38200946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B1', 'B2', 'A2/A2+', 'C1', 'B1, B2', 'A2/A2+, B1', 'A2', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Level_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "060bef88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'A2', 'B1', 'B2', 'C1'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Level_y'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70f04a",
   "metadata": {},
   "source": [
    "Иногда указывают несколько уровней языка для одного фильма (А2, В1). Пока я оставлю самый высокий, это проще. Можно отложить эти сомнительные фильмы и потом определить обученной моделью их уровень. Уровень А2/А2+ заменяем на А2, потому что у нас не стоит задачи в градации подуровней внутри уровня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "386b07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Level_x'] = df_all['Level_x'].replace('A2/A2+', 'A2')\n",
    "df_all['Level_x'] = df_all['Level_x'].replace('A2/A2+, B1', 'B1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f871802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Level_x'] = df_all['Level_x'].replace('B1, B2', 'B2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40706079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B1', 'B2', 'A2', 'C1', nan], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Level_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a342e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Строк с разными значениями в столбцах Label_x и Label_y: 0\n"
     ]
    }
   ],
   "source": [
    "print('Строк с разными значениями в столбцах Label_x и Label_y:',\\\n",
    "    len(df_all.loc[(df_all['Level_x'].notna())&(df_all['Level_y'].notna()) & (df_all['Level_x']!=df_all['Level_y'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0c33e",
   "metadata": {},
   "source": [
    "Значит, просто заполним пропуски переносом значений из одного стобца в другой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "278d43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Level']=df_all['Level_x'].fillna(df_all['Level_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11f683e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B1', 'B2', 'A2', 'C1', nan], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "206eb7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290 entries, 0 to 289\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Movie    290 non-null    object\n",
      " 1   Level_x  241 non-null    object\n",
      " 2   Srt_x    119 non-null    object\n",
      " 3   Level_y  163 non-null    object\n",
      " 4   Srt_y    163 non-null    object\n",
      " 5   Level    281 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 13.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47150a1",
   "metadata": {},
   "source": [
    "Также проверим, есть ли несовпадения по субтитрам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd6f1d42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Строк с разными значениями в столбцах Srt_x и Srt_y: 0\n"
     ]
    }
   ],
   "source": [
    "print('Строк с разными значениями в столбцах Srt_x и Srt_y:',\\\n",
    "    len(df_all.loc[(df_all['Srt_x'].notna())&(df_all['Srt_y'].notna()) & (df_all['Srt_x']!=df_all['Srt_y'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c12bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Srt']=df_all['Srt_x'].fillna(df_all['Srt_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b736595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290 entries, 0 to 289\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Movie    290 non-null    object\n",
      " 1   Level_x  241 non-null    object\n",
      " 2   Srt_x    119 non-null    object\n",
      " 3   Level_y  163 non-null    object\n",
      " 4   Srt_y    163 non-null    object\n",
      " 5   Level    281 non-null    object\n",
      " 6   Srt      282 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 16.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a1c6250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Movie', 'Level_x', 'Srt_x', 'Level_y', 'Srt_y', 'Level', 'Srt'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc8c3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.copy().drop(columns=['Level_x', 'Srt_x', 'Level_y', 'Srt_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dca17871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290 entries, 0 to 289\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Movie   290 non-null    object\n",
      " 1   Level   281 non-null    object\n",
      " 2   Srt     282 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e1571a",
   "metadata": {},
   "source": [
    "Если пропуски в разных строках, то удалится в общей сложности 17 строк. Пока восстанавливать пропущенные значения не буду - надо смочь выполнить работу в минимальном объёме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95ae3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grade = df.loc[(df['Level'].isna())&(df['Srt'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0fcf3",
   "metadata": {},
   "source": [
    "Отделяю фильмы с субтитрами, но неопределённым уровнем языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "478aff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "      <th>Srt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Breaking_Bad_The_Movie(2017)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1\\n00:00:05,299 --&gt; 00:00:08,220\\nwhat hi good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Bren╨Т.Brown.The.Call.to.Courage.2019.720.NF.7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ï»¿1\\n00:00:07,216 --&gt; 00:00:09,676\\n[presente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Casper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1\\n00:00:18,040 --&gt; 00:00:21,870\\n[Music]\\n\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Gogo_Loves_English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1\\n00:00:01,130 --&gt; 00:00:18,359\\n[Music]\\n\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Harry_Potter_and_the_philosophers_stone(2001)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1\\n00:01:22,065 --&gt; 00:01:27,070\\nI should've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Pride_and_Prejudice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1\\n00:00:20,020 --&gt; 00:00:42,009\\n[Music]\\n\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>The_Ghost_Writer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1\\n00:00:04,670 --&gt; 00:00:18,579\\n[Music]\\n\\n2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Up(2009)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1\\n00:00:46,040 --&gt; 00:00:50,960\\n{\\i1}Movieto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Westworld_scenes_of_Dr_Robert_Ford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1\\n00:00:00,000 --&gt; 00:00:21,179\\n[Music]\\n\\n2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Movie Level  \\\n",
       "241                       Breaking_Bad_The_Movie(2017)   NaN   \n",
       "242  Bren╨Т.Brown.The.Call.to.Courage.2019.720.NF.7...   NaN   \n",
       "243                                             Casper   NaN   \n",
       "244                                 Gogo_Loves_English   NaN   \n",
       "245      Harry_Potter_and_the_philosophers_stone(2001)   NaN   \n",
       "246                                Pride_and_Prejudice   NaN   \n",
       "247                                   The_Ghost_Writer   NaN   \n",
       "248                                           Up(2009)   NaN   \n",
       "249                 Westworld_scenes_of_Dr_Robert_Ford   NaN   \n",
       "\n",
       "                                                   Srt  \n",
       "241  1\\n00:00:05,299 --> 00:00:08,220\\nwhat hi good...  \n",
       "242  ï»¿1\\n00:00:07,216 --> 00:00:09,676\\n[presente...  \n",
       "243  1\\n00:00:18,040 --> 00:00:21,870\\n[Music]\\n\\n2...  \n",
       "244  1\\n00:00:01,130 --> 00:00:18,359\\n[Music]\\n\\n2...  \n",
       "245  1\\n00:01:22,065 --> 00:01:27,070\\nI should've ...  \n",
       "246  1\\n00:00:20,020 --> 00:00:42,009\\n[Music]\\n\\n2...  \n",
       "247  1\\n00:00:04,670 --> 00:00:18,579\\n[Music]\\n\\n2...  \n",
       "248  1\\n00:00:46,040 --> 00:00:50,960\\n{\\i1}Movieto...  \n",
       "249  1\\n00:00:00,000 --> 00:00:21,179\\n[Music]\\n\\n2...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1128226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Level', 'Srt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa88b86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 273 entries, 0 to 289\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Movie   273 non-null    object\n",
      " 1   Level   273 non-null    object\n",
      " 2   Srt     273 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 8.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f05b0",
   "metadata": {},
   "source": [
    "Теперь посмотрим на дубли. Найдём - удалим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "213d3a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12fdafb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "      <th>Srt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "      <td>1\\n00:00:55,279 --&gt; 00:01:07,279\\n&lt;font color=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "      <td>1\\n00:01:54,281 --&gt; 00:01:55,698\\nHey!\\n\\n2\\n0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:15,089 --&gt; 00:00:21,229\\nResync: Xenz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:17,610 --&gt; 00:00:22,610\\n- &lt;i&gt;&lt;font c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2</td>\n",
       "      <td>1\\n00:00:27,240 --&gt; 00:00:30,879\\n&lt;i&gt;Oh, I com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>All_dogs_go_to_heaven(1989)</td>\n",
       "      <td>A2</td>\n",
       "      <td>1\\n00:00:12,319 --&gt; 00:00:14,821\\nCAPTIONING M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>An_American_tail(1986)</td>\n",
       "      <td>A2</td>\n",
       "      <td>ï»¿1\\n00:02:24,080 --&gt; 00:02:26,528\\n(INDISTIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Babe(1995)</td>\n",
       "      <td>A2</td>\n",
       "      <td>0\\n00:02:31,114 --&gt; 00:02:34,316\\nThis is a ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                             Movie Level  \\\n",
       "0      0         10_Cloverfield_lane(2016)    B1   \n",
       "1      1  10_things_I_hate_about_you(1999)    B1   \n",
       "2      2              A_knights_tale(2001)    B2   \n",
       "3      3              A_star_is_born(2018)    B2   \n",
       "4      4                     Aladdin(1992)    A2   \n",
       "5      5       All_dogs_go_to_heaven(1989)    A2   \n",
       "6      6            An_American_tail(1986)    A2   \n",
       "7      7                        Babe(1995)    A2   \n",
       "\n",
       "                                                 Srt  \n",
       "0  1\\n00:00:55,279 --> 00:01:07,279\\n<font color=...  \n",
       "1  1\\n00:01:54,281 --> 00:01:55,698\\nHey!\\n\\n2\\n0...  \n",
       "2  1\\n00:00:15,089 --> 00:00:21,229\\nResync: Xenz...  \n",
       "3  1\\n00:00:17,610 --> 00:00:22,610\\n- <i><font c...  \n",
       "4  1\\n00:00:27,240 --> 00:00:30,879\\n<i>Oh, I com...  \n",
       "5  1\\n00:00:12,319 --> 00:00:14,821\\nCAPTIONING M...  \n",
       "6  ï»¿1\\n00:02:24,080 --> 00:02:26,528\\n(INDISTIN...  \n",
       "7  0\\n00:02:31,114 --> 00:02:34,316\\nThis is a ta...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()\n",
    "df = df.reset_index()\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4682ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "      <th>Srt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "      <td>1\\n00:00:55,279 --&gt; 00:01:07,279\\n&lt;font color=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "      <td>1\\n00:01:54,281 --&gt; 00:01:55,698\\nHey!\\n\\n2\\n0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:15,089 --&gt; 00:00:21,229\\nResync: Xenz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:17,610 --&gt; 00:00:22,610\\n- &lt;i&gt;&lt;font c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2</td>\n",
       "      <td>1\\n00:00:27,240 --&gt; 00:00:30,879\\n&lt;i&gt;Oh, I com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Virgin.River.S01E06.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:18,852 --&gt; 00:00:19,852\\nHey.\\n\\n2\\n0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:10,468 --&gt; 00:00:13,178\\nAre you sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Virgin.River.S01E08.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:07,382 --&gt; 00:00:10,012\\nTwo IVs in p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Virgin.River.S01E09.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:16,474 --&gt; 00:00:18,024\\nOh.\\n\\n2\\n00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Virgin.River.S01E10.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>1\\n00:00:07,424 --&gt; 00:00:08,844\\nSo, how long...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Movie Level  \\\n",
       "0                            10_Cloverfield_lane(2016)    B1   \n",
       "1                     10_things_I_hate_about_you(1999)    B1   \n",
       "2                                 A_knights_tale(2001)    B2   \n",
       "3                                 A_star_is_born(2018)    B2   \n",
       "4                                        Aladdin(1992)    A2   \n",
       "..                                                 ...   ...   \n",
       "268  Virgin.River.S01E06.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "269  Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "270  Virgin.River.S01E08.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "271  Virgin.River.S01E09.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "272  Virgin.River.S01E10.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "\n",
       "                                                   Srt  \n",
       "0    1\\n00:00:55,279 --> 00:01:07,279\\n<font color=...  \n",
       "1    1\\n00:01:54,281 --> 00:01:55,698\\nHey!\\n\\n2\\n0...  \n",
       "2    1\\n00:00:15,089 --> 00:00:21,229\\nResync: Xenz...  \n",
       "3    1\\n00:00:17,610 --> 00:00:22,610\\n- <i><font c...  \n",
       "4    1\\n00:00:27,240 --> 00:00:30,879\\n<i>Oh, I com...  \n",
       "..                                                 ...  \n",
       "268  1\\n00:00:18,852 --> 00:00:19,852\\nHey.\\n\\n2\\n0...  \n",
       "269  1\\n00:00:10,468 --> 00:00:13,178\\nAre you sure...  \n",
       "270  1\\n00:00:07,382 --> 00:00:10,012\\nTwo IVs in p...  \n",
       "271  1\\n00:00:16,474 --> 00:00:18,024\\nOh.\\n\\n2\\n00...  \n",
       "272  1\\n00:00:07,424 --> 00:00:08,844\\nSo, how long...  \n",
       "\n",
       "[273 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "118b76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_1, df_2, df_3, df_2_3, df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357aecf",
   "metadata": {},
   "source": [
    "Удалила уже ненужные переменные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f438b",
   "metadata": {},
   "source": [
    "### Обработка субтитров\n",
    "\n",
    "Необходимо преобразовать текст в числовую форму, удобную для моделирования.\n",
    "\n",
    "Избавимся от лишних символов, стоп-слов и скобок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7382b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english') + [\"im\", \"ill\", \"oh\", \"hey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee10749",
   "metadata": {},
   "source": [
    "Нужно оставить только текст, поэтому с помощью регулярных выражений удалим ненужное - небуквенные символы, содержимое скобок, html-теги, переносы, пробелы больше одного подряд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72a0c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_n = re.compile('\\n')                  # перенос каретки\n",
    "del_tags = re.compile('<[^>]*>')          # html-теги\n",
    "del_brackets = re.compile('\\([^)]*\\)')    # содержимое круглых скобок\n",
    "clean_text = re.compile('[^а-яa-z\\s]')  # все небуквенные символы кроме пробелов\n",
    "del_spaces = re.compile('\\s{2,}')         \n",
    "\n",
    "def prepare_text(text):\n",
    "    text = del_n.sub(' ', str(text).lower())\n",
    "    text = del_tags.sub('', text)\n",
    "    text = del_brackets.sub('', text)\n",
    "    res_text = clean_text.sub('', text)\n",
    "    res_text = res_text.lower()  #перевод в нижний регистр\n",
    "    return del_spaces.sub(' ',res_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a74228",
   "metadata": {},
   "source": [
    "Следующая функция разбивает текст субтитров на слова и удаляет те, которые встречаются в списке стоп-слов.\n",
    "Пока не очень понимаю, пригодится ли длина первоначального текста, но я её посчитаю. И длину образовавшегося массива слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3be2f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stop_words(Sr, stop):\n",
    "\n",
    "    for itm in range(len(Sr)):\n",
    "        line = Sr[itm]\n",
    "        line = prepare_text(line)\n",
    "        line = [w for w in line.split() if w not in stop]\n",
    "        Sr[itm] = line\n",
    "    return Sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77a41462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Srt'] = df_stop_words(df['Srt'], stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "647aeb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "      <th>Srt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "      <td>[fixed, synced, bozxphd, enjoy, flick, ben, ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "      <td>[right, cameron, go, nine, schools, years, arm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "      <td>[resync, xenzainef, retail, help, hes, due, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "      <td>[synced, corrected, mrcjnthn, get, black, eyes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2</td>\n",
       "      <td>[come, land, faraway, place, caravan, camels, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>All_dogs_go_to_heaven(1989)</td>\n",
       "      <td>A2</td>\n",
       "      <td>[captioning, made, possible, mgm, home, entert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>An_American_tail(1986)</td>\n",
       "      <td>A2</td>\n",
       "      <td>[mama, tanya, fievel, stop, twirling, twirling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Babe(1995)</td>\n",
       "      <td>A2</td>\n",
       "      <td>[tale, aboutan, unprejudiced, heart, changed, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                             Movie Level  \\\n",
       "0      0         10_Cloverfield_lane(2016)    B1   \n",
       "1      1  10_things_I_hate_about_you(1999)    B1   \n",
       "2      2              A_knights_tale(2001)    B2   \n",
       "3      3              A_star_is_born(2018)    B2   \n",
       "4      4                     Aladdin(1992)    A2   \n",
       "5      5       All_dogs_go_to_heaven(1989)    A2   \n",
       "6      6            An_American_tail(1986)    A2   \n",
       "7      7                        Babe(1995)    A2   \n",
       "\n",
       "                                                 Srt  \n",
       "0  [fixed, synced, bozxphd, enjoy, flick, ben, ph...  \n",
       "1  [right, cameron, go, nine, schools, years, arm...  \n",
       "2  [resync, xenzainef, retail, help, hes, due, li...  \n",
       "3  [synced, corrected, mrcjnthn, get, black, eyes...  \n",
       "4  [come, land, faraway, place, caravan, camels, ...  \n",
       "5  [captioning, made, possible, mgm, home, entert...  \n",
       "6  [mama, tanya, fievel, stop, twirling, twirling...  \n",
       "7  [tale, aboutan, unprejudiced, heart, changed, ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4316ea0",
   "metadata": {},
   "source": [
    "Теперь проведём лемматизацию - приведём слова к корневой форме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c74e4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer = WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9a42d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise_srt(Sr):\n",
    "    for itm in range(len(Sr)):\n",
    "        line = Sr[itm]\n",
    "        line = [porter.stem(word) for word in line]\n",
    "        Sr[itm] =  str(line)\n",
    "    return Sr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68f74e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Srt'] = lemmatise_srt(df['Srt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5de343cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "      <th>Srt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "      <td>['fix', 'sync', 'bozxphd', 'enjoy', 'flick', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "      <td>['right', 'cameron', 'go', 'nine', 'school', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "      <td>['resync', 'xenzainef', 'retail', 'help', 'he'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "      <td>['sync', 'correct', 'mrcjnthn', 'get', 'black'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2</td>\n",
       "      <td>['come', 'land', 'faraway', 'place', 'caravan'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Virgin.River.S01E06.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>['wouldnt', 'chainsaw', 'easier', 'yeah', 'muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>['sure', 'cant', 'convinc', 'stay', 'right', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Virgin.River.S01E08.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>['two', 'iv', 'place', 'antecubit', 'fossa', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Virgin.River.S01E09.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>['yeah', 'okay', 'right', 'yeah', 'okay', 'hi'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Virgin.River.S01E10.INTERNAL.720p.WEB.x264-STRiFE</td>\n",
       "      <td>B2</td>\n",
       "      <td>['long', 'known', 'ive', 'suspect', 'coupl', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Movie Level  \\\n",
       "0                            10_Cloverfield_lane(2016)    B1   \n",
       "1                     10_things_I_hate_about_you(1999)    B1   \n",
       "2                                 A_knights_tale(2001)    B2   \n",
       "3                                 A_star_is_born(2018)    B2   \n",
       "4                                        Aladdin(1992)    A2   \n",
       "..                                                 ...   ...   \n",
       "268  Virgin.River.S01E06.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "269  Virgin.River.S01E07.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "270  Virgin.River.S01E08.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "271  Virgin.River.S01E09.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "272  Virgin.River.S01E10.INTERNAL.720p.WEB.x264-STRiFE    B2   \n",
       "\n",
       "                                                   Srt  \n",
       "0    ['fix', 'sync', 'bozxphd', 'enjoy', 'flick', '...  \n",
       "1    ['right', 'cameron', 'go', 'nine', 'school', '...  \n",
       "2    ['resync', 'xenzainef', 'retail', 'help', 'he'...  \n",
       "3    ['sync', 'correct', 'mrcjnthn', 'get', 'black'...  \n",
       "4    ['come', 'land', 'faraway', 'place', 'caravan'...  \n",
       "..                                                 ...  \n",
       "268  ['wouldnt', 'chainsaw', 'easier', 'yeah', 'muc...  \n",
       "269  ['sure', 'cant', 'convinc', 'stay', 'right', '...  \n",
       "270  ['two', 'iv', 'place', 'antecubit', 'fossa', '...  \n",
       "271  ['yeah', 'okay', 'right', 'yeah', 'okay', 'hi'...  \n",
       "272  ['long', 'known', 'ive', 'suspect', 'coupl', '...  \n",
       "\n",
       "[273 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['index'])  #.to_csv('movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c10b34",
   "metadata": {},
   "source": [
    "###### Теперь приступим к векторизации.\n",
    "\n",
    "Поскольку в будущем модель должна будет работать с неопределённым набором слов из текста, для векторизации необходимо создать некоторый словарь, который определит количество и состав фичей в модели. Пока я строю одну модель на все уровни, соберу один словарь. В дальнейшем можно обучить несколько моделей, на каждый уровень языка свою, тогда словари будут не такие большие и только на свой уровень. Но это в будущем.\n",
    "\n",
    "Нам предоставлены словари с градацией по уровням, американские и британские в формате pdf. У них есть текстовый слой, скопирую вручную в отдельный файлик 'dict.xlsx', потом его преобразую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d4a87a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_eng = pd.read_excel('dict.xlsx')\n",
    "dict_eng.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95281b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ability n.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able adj.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accept v.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accident n.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>according to prep.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>worship n., v.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>worthwhile adj.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>worthy adj.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>yell v.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>yield</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4439 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   words\n",
       "0             ability n.\n",
       "1              able adj.\n",
       "2              accept v.\n",
       "3            accident n.\n",
       "4     according to prep.\n",
       "...                  ...\n",
       "4434      worship n., v.\n",
       "4435     worthwhile adj.\n",
       "4436         worthy adj.\n",
       "4437             yell v.\n",
       "4438               yield\n",
       "\n",
       "[4439 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66322a4a",
   "metadata": {},
   "source": [
    "Нужно почистить слова от частей речи, предлогов и также лемматизировать. Дубли после этого удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efa83568",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stop + ['ah', 'adj', 'n', 'v', 'prep', 'conj', 'pron', 'modal v', 'adv', 'adjadv', 'detpron', 'modal', 'exclam', 'number', 'nadj' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "241e7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_eng['words'] = df_stop_words(dict_eng['words'], stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e37c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_eng['words'] = lemmatise_srt(dict_eng['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95d29d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "977"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_eng.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1da70664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_eng = dict_eng.drop_duplicates().reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "163238c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(Sr):\n",
    "    for itm in range(len(Sr)):\n",
    "        line = Sr[itm]\n",
    "        if line=='':\n",
    "            Sr[itm]=np.nan\n",
    "        else:\n",
    "            Sr[itm] = str(prepare_text(line))\n",
    "            \n",
    "    return Sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3546699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_eng['words'] = to_words(dict_eng['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "750f7185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_eng.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1ffba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_eng['words'] = to_words(dict_eng['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "daf40ded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_eng.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1f472",
   "metadata": {},
   "source": [
    "По непонятной мне причине не опустошается строка с первого раза. Что-то я делаю не так."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "981a18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_eng = dict_eng.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f57e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_eng = dict_eng.loc[dict_eng.index!=14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f79e2a",
   "metadata": {},
   "source": [
    "Теперь нужно сделать из этого словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50db1e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abil': 0,\n",
       " 'abl': 1,\n",
       " 'accept': 2,\n",
       " 'accid': 3,\n",
       " 'accord': 4,\n",
       " 'achiev': 5,\n",
       " 'act': 6,\n",
       " 'activ': 7,\n",
       " 'actual': 8,\n",
       " 'adult': 9,\n",
       " 'advantag': 10,\n",
       " 'adventur': 11,\n",
       " 'advertis': 12,\n",
       " 'affect': 13,\n",
       " 'airlin': 14,\n",
       " 'aliv': 15,\n",
       " 'right': 16,\n",
       " 'allow': 17,\n",
       " 'almost': 18,\n",
       " 'alon': 19,\n",
       " 'along': 20,\n",
       " 'alreadi': 21,\n",
       " 'altern': 22,\n",
       " 'although': 23,\n",
       " 'among': 24,\n",
       " 'amount': 25,\n",
       " 'analyz': 26,\n",
       " 'ancient': 27,\n",
       " 'ankl': 28,\n",
       " 'anybodi': 29,\n",
       " 'anymor': 30,\n",
       " 'anyway': 31,\n",
       " 'anywher': 32,\n",
       " 'app': 33,\n",
       " 'appear': 34,\n",
       " 'appli': 35,\n",
       " 'architect': 36,\n",
       " 'architectur': 37,\n",
       " 'argu': 38,\n",
       " 'argument': 39,\n",
       " 'armi': 40,\n",
       " 'arrang': 41,\n",
       " 'asleep': 42,\n",
       " 'assist': 43,\n",
       " 'athlet': 44,\n",
       " 'attack': 45,\n",
       " 'attend': 46,\n",
       " 'attent': 47,\n",
       " 'attract': 48,\n",
       " 'audienc': 49,\n",
       " 'author': 50,\n",
       " 'avail': 51,\n",
       " 'averag': 52,\n",
       " 'avoid': 53,\n",
       " 'award': 54,\n",
       " 'aw': 55,\n",
       " 'back': 56,\n",
       " 'background': 57,\n",
       " 'badli': 58,\n",
       " 'base': 59,\n",
       " 'bean': 60,\n",
       " 'bear': 61,\n",
       " 'beat': 62,\n",
       " 'beef': 63,\n",
       " 'behav': 64,\n",
       " 'behavior': 65,\n",
       " 'belong': 66,\n",
       " 'belt': 67,\n",
       " 'benefit': 68,\n",
       " 'best': 69,\n",
       " 'better': 70,\n",
       " 'billion': 71,\n",
       " 'biolog': 72,\n",
       " 'birth': 73,\n",
       " 'bit': 74,\n",
       " 'blank': 75,\n",
       " 'block': 76,\n",
       " 'blood': 77,\n",
       " 'blow': 78,\n",
       " 'board': 79,\n",
       " 'boil': 80,\n",
       " 'bone': 81,\n",
       " 'book': 82,\n",
       " 'borrow': 83,\n",
       " 'boss': 84,\n",
       " 'bottom': 85,\n",
       " 'bowl': 86,\n",
       " 'brain': 87,\n",
       " 'bridg': 88,\n",
       " 'bright': 89,\n",
       " 'brilliant': 90,\n",
       " 'broken': 91,\n",
       " 'brush': 92,\n",
       " 'burn': 93,\n",
       " 'businessman': 94,\n",
       " 'button': 95,\n",
       " 'camp': 96,\n",
       " 'campu': 97,\n",
       " 'candi': 98,\n",
       " 'care': 99,\n",
       " 'carpet': 100,\n",
       " 'cartoon': 101,\n",
       " 'case': 102,\n",
       " 'cash': 103,\n",
       " 'catch': 104,\n",
       " 'caus': 105,\n",
       " 'celebr': 106,\n",
       " 'cell': 107,\n",
       " 'centuri': 108,\n",
       " 'certain': 109,\n",
       " 'certainli': 110,\n",
       " 'chanc': 111,\n",
       " 'charact': 112,\n",
       " 'chariti': 113,\n",
       " 'chat': 114,\n",
       " 'check': 115,\n",
       " 'chef': 116,\n",
       " 'chemistri': 117,\n",
       " 'chip': 118,\n",
       " 'choic': 119,\n",
       " 'church': 120,\n",
       " 'cigarett': 121,\n",
       " 'circl': 122,\n",
       " 'classic': 123,\n",
       " 'clear': 124,\n",
       " 'clearli': 125,\n",
       " 'clerk': 126,\n",
       " 'climat': 127,\n",
       " 'close': 128,\n",
       " 'closet': 129,\n",
       " 'cloth': 130,\n",
       " 'cloud': 131,\n",
       " 'coach': 132,\n",
       " 'coast': 133,\n",
       " 'code': 134,\n",
       " 'colleagu': 135,\n",
       " 'collect': 136,\n",
       " 'column': 137,\n",
       " 'comedi': 138,\n",
       " 'comfort': 139,\n",
       " 'comment': 140,\n",
       " 'commun': 141,\n",
       " 'compet': 142,\n",
       " 'competit': 143,\n",
       " 'complain': 144,\n",
       " 'nan': 145,\n",
       " 'complet': 146,\n",
       " 'condit': 147,\n",
       " 'confer': 148,\n",
       " 'connect': 149,\n",
       " 'consid': 150,\n",
       " 'contain': 151,\n",
       " 'context': 152,\n",
       " 'contin': 153,\n",
       " 'continu': 154,\n",
       " 'control': 155,\n",
       " 'cook': 156,\n",
       " 'cooki': 157,\n",
       " 'copi': 158,\n",
       " 'corner': 159,\n",
       " 'correctli': 160,\n",
       " 'count': 161,\n",
       " 'coupl': 162,\n",
       " 'cover': 163,\n",
       " 'crazi': 164,\n",
       " 'creativ': 165,\n",
       " 'credit': 166,\n",
       " 'crime': 167,\n",
       " 'crimin': 168,\n",
       " 'cross': 169,\n",
       " 'crowd': 170,\n",
       " 'cri': 171,\n",
       " 'curli': 172,\n",
       " 'cycl': 173,\n",
       " 'daili': 174,\n",
       " 'danger': 175,\n",
       " 'dark': 176,\n",
       " 'data': 177,\n",
       " 'dead': 178,\n",
       " 'deal': 179,\n",
       " 'death': 180,\n",
       " 'decis': 181,\n",
       " 'deep': 182,\n",
       " 'definit': 183,\n",
       " 'degre': 184,\n",
       " 'dentist': 185,\n",
       " 'depart': 186,\n",
       " 'depend': 187,\n",
       " 'desert': 188,\n",
       " 'design': 189,\n",
       " 'dessert': 190,\n",
       " 'destroy': 191,\n",
       " 'detect': 192,\n",
       " 'develop': 193,\n",
       " 'devic': 194,\n",
       " 'diari': 195,\n",
       " 'differ': 196,\n",
       " 'digit': 197,\n",
       " 'direct': 198,\n",
       " 'director': 199,\n",
       " 'disagre': 200,\n",
       " 'disappear': 201,\n",
       " 'disast': 202,\n",
       " 'discov': 203,\n",
       " 'discoveri': 204,\n",
       " 'discuss': 205,\n",
       " 'diseas': 206,\n",
       " 'distanc': 207,\n",
       " 'divorc': 208,\n",
       " 'document': 209,\n",
       " 'doubl det': 210,\n",
       " 'download': 211,\n",
       " 'downstair': 212,\n",
       " 'downtown': 213,\n",
       " 'drama': 214,\n",
       " 'draw': 215,\n",
       " 'dream': 216,\n",
       " 'drive': 217,\n",
       " 'drop': 218,\n",
       " 'drug': 219,\n",
       " 'dri': 220,\n",
       " 'earn': 221,\n",
       " 'earth': 222,\n",
       " 'easili': 223,\n",
       " 'educ': 224,\n",
       " 'effect': 225,\n",
       " 'either': 226,\n",
       " 'electr': 227,\n",
       " 'electron': 228,\n",
       " 'elev': 229,\n",
       " 'employ': 230,\n",
       " 'employe': 231,\n",
       " 'empti': 232,\n",
       " 'end': 233,\n",
       " 'energi': 234,\n",
       " 'engin': 235,\n",
       " 'enorm': 236,\n",
       " 'enter': 237,\n",
       " 'environ': 238,\n",
       " 'equip': 239,\n",
       " 'error': 240,\n",
       " 'especi': 241,\n",
       " 'essay': 242,\n",
       " 'everyday': 243,\n",
       " 'everywher': 244,\n",
       " 'evid': 245,\n",
       " 'exact': 246,\n",
       " 'exactli': 247,\n",
       " 'excel': 248,\n",
       " 'except': 249,\n",
       " 'exist': 250,\n",
       " 'expect': 251,\n",
       " 'experi': 252,\n",
       " 'expert': 253,\n",
       " 'explan': 254,\n",
       " 'express': 255,\n",
       " 'extrem': 256,\n",
       " 'factor': 257,\n",
       " 'factori': 258,\n",
       " 'fail': 259,\n",
       " 'fair': 260,\n",
       " 'fan': 261,\n",
       " 'farm': 262,\n",
       " 'fashion': 263,\n",
       " 'fat': 264,\n",
       " 'fear': 265,\n",
       " 'featur': 266,\n",
       " 'feed': 267,\n",
       " 'femal': 268,\n",
       " 'fever': 269,\n",
       " 'fiction': 270,\n",
       " 'field': 271,\n",
       " 'fight': 272,\n",
       " 'figur': 273,\n",
       " 'film': 274,\n",
       " 'final': 275,\n",
       " 'finger': 276,\n",
       " 'finish': 277,\n",
       " 'fire': 278,\n",
       " 'first': 279,\n",
       " 'fish': 280,\n",
       " 'fit': 281,\n",
       " 'fix': 282,\n",
       " 'flat': 283,\n",
       " 'flu': 284,\n",
       " 'fli': 285,\n",
       " 'focu': 286,\n",
       " 'follow': 287,\n",
       " 'foreign': 288,\n",
       " 'forest': 289,\n",
       " 'fork': 290,\n",
       " 'formal': 291,\n",
       " 'fortun': 292,\n",
       " 'forward': 293,\n",
       " 'free': 294,\n",
       " 'fresh': 295,\n",
       " 'frog': 296,\n",
       " 'fun': 297,\n",
       " 'furnitur': 298,\n",
       " 'futur': 299,\n",
       " 'galleri': 300,\n",
       " 'gap': 301,\n",
       " 'garbag': 302,\n",
       " 'ga': 303,\n",
       " 'gate': 304,\n",
       " 'gener': 305,\n",
       " 'gift': 306,\n",
       " 'goal': 307,\n",
       " 'god': 308,\n",
       " 'gold': 309,\n",
       " 'golf': 310,\n",
       " 'good': 311,\n",
       " 'govern': 312,\n",
       " 'grass': 313,\n",
       " 'greet': 314,\n",
       " 'groceri': 315,\n",
       " 'ground': 316,\n",
       " 'guest': 317,\n",
       " 'guid': 318,\n",
       " 'gun': 319,\n",
       " 'guy': 320,\n",
       " 'habit': 321,\n",
       " 'half': 322,\n",
       " 'hall': 323,\n",
       " 'happili': 324,\n",
       " 'auxiliari': 325,\n",
       " 'headach': 326,\n",
       " 'heart': 327,\n",
       " 'heat': 328,\n",
       " 'heavi': 329,\n",
       " 'height': 330,\n",
       " 'help': 331,\n",
       " 'hero': 332,\n",
       " 'hide': 333,\n",
       " 'high': 334,\n",
       " 'hill': 335,\n",
       " 'hit': 336,\n",
       " 'hockey': 337,\n",
       " 'hold': 338,\n",
       " 'hole': 339,\n",
       " 'holiday': 340,\n",
       " 'home': 341,\n",
       " 'hope': 342,\n",
       " 'huge': 343,\n",
       " 'human': 344,\n",
       " 'hurt': 345,\n",
       " 'ideal': 346,\n",
       " 'identifi': 347,\n",
       " 'ill': 348,\n",
       " 'imag': 349,\n",
       " 'immedi': 350,\n",
       " 'imposs': 351,\n",
       " 'includ': 352,\n",
       " 'increas': 353,\n",
       " 'incred': 354,\n",
       " 'independ': 355,\n",
       " 'individu': 356,\n",
       " 'industri': 357,\n",
       " 'inform': 358,\n",
       " 'injuri': 359,\n",
       " 'insect': 360,\n",
       " 'insid': 361,\n",
       " 'instead': 362,\n",
       " 'instruct': 363,\n",
       " 'instructor': 364,\n",
       " 'instrument': 365,\n",
       " 'intellig': 366,\n",
       " 'intern': 367,\n",
       " 'introduct': 368,\n",
       " 'invent': 369,\n",
       " 'invit': 370,\n",
       " 'involv': 371,\n",
       " 'item': 372,\n",
       " 'jam': 373,\n",
       " 'jazz': 374,\n",
       " 'jewelri': 375,\n",
       " 'joke': 376,\n",
       " 'journalist': 377,\n",
       " 'jump': 378,\n",
       " 'kid': 379,\n",
       " 'kill': 380,\n",
       " 'kilomet': 381,\n",
       " 'king': 382,\n",
       " 'knee': 383,\n",
       " 'knife': 384,\n",
       " 'knock': 385,\n",
       " 'knowledg': 386,\n",
       " 'lab': 387,\n",
       " 'ladi': 388,\n",
       " 'lake': 389,\n",
       " 'lamp': 390,\n",
       " 'land': 391,\n",
       " 'laptop': 392,\n",
       " 'last': 393,\n",
       " 'later': 394,\n",
       " 'laughter': 395,\n",
       " 'law': 396,\n",
       " 'lawyer': 397,\n",
       " 'lazi': 398,\n",
       " 'lead': 399,\n",
       " 'leader': 400,\n",
       " 'learn': 401,\n",
       " 'least': 402,\n",
       " 'lectur': 403,\n",
       " 'lemon': 404,\n",
       " 'lend': 405,\n",
       " 'less': 406,\n",
       " 'level': 407,\n",
       " 'lifestyl': 408,\n",
       " 'lift': 409,\n",
       " 'light': 410,\n",
       " 'like': 411,\n",
       " 'link': 412,\n",
       " 'listen': 413,\n",
       " 'littl': 414,\n",
       " 'lock': 415,\n",
       " 'look': 416,\n",
       " 'lost': 417,\n",
       " 'loud': 418,\n",
       " 'loudli': 419,\n",
       " 'low': 420,\n",
       " 'luck': 421,\n",
       " 'lucki': 422,\n",
       " 'mail': 423,\n",
       " 'major': 424,\n",
       " 'male': 425,\n",
       " 'manag': 426,\n",
       " 'manner': 427,\n",
       " 'mark': 428,\n",
       " 'marri': 429,\n",
       " 'materi': 430,\n",
       " 'math': 431,\n",
       " 'mathemat': 432,\n",
       " 'matter': 433,\n",
       " 'may': 434,\n",
       " 'mayor': 435,\n",
       " 'media': 436,\n",
       " 'medic': 437,\n",
       " 'medicin': 438,\n",
       " 'memori': 439,\n",
       " 'mention': 440,\n",
       " 'metal': 441,\n",
       " 'method': 442,\n",
       " 'middl': 443,\n",
       " 'might': 444,\n",
       " 'mind': 445,\n",
       " 'mine': 446,\n",
       " 'mirror': 447,\n",
       " 'miss': 448,\n",
       " 'monkey': 449,\n",
       " 'moon': 450,\n",
       " 'mostli': 451,\n",
       " 'motorcycl': 452,\n",
       " 'movement': 453,\n",
       " 'music': 454,\n",
       " 'musician': 455,\n",
       " 'narrow': 456,\n",
       " 'nation': 457,\n",
       " 'natur': 458,\n",
       " 'nearli': 459,\n",
       " 'necessari': 460,\n",
       " 'neck': 461,\n",
       " 'need': 462,\n",
       " 'neither': 463,\n",
       " 'nervou': 464,\n",
       " 'network': 465,\n",
       " 'nois': 466,\n",
       " 'noisi': 467,\n",
       " 'none': 468,\n",
       " 'normal': 469,\n",
       " 'notic': 470,\n",
       " 'novel': 471,\n",
       " 'nowher': 472,\n",
       " 'nut': 473,\n",
       " 'offer': 474,\n",
       " 'offic': 475,\n",
       " 'oil': 476,\n",
       " 'onto': 477,\n",
       " 'opportun': 478,\n",
       " 'option': 479,\n",
       " 'ordinari': 480,\n",
       " 'organ': 481,\n",
       " 'origin': 482,\n",
       " 'outsid': 483,\n",
       " 'oven': 484,\n",
       " 'oversea': 485,\n",
       " 'owner': 486,\n",
       " 'pack': 487,\n",
       " 'pain': 488,\n",
       " 'painter': 489,\n",
       " 'palac': 490,\n",
       " 'park': 491,\n",
       " 'particular': 492,\n",
       " 'pass': 493,\n",
       " 'passeng': 494,\n",
       " 'past': 495,\n",
       " 'patient': 496,\n",
       " 'pattern': 497,\n",
       " 'pay': 498,\n",
       " 'peac': 499,\n",
       " 'penni': 500,\n",
       " 'per': 501,\n",
       " 'percent noun': 502,\n",
       " 'perform': 503,\n",
       " 'perhap': 504,\n",
       " 'permiss': 505,\n",
       " 'person': 506,\n",
       " 'pet': 507,\n",
       " 'photograph': 508,\n",
       " 'physic': 509,\n",
       " 'pick': 510,\n",
       " 'pilot': 511,\n",
       " 'planet': 512,\n",
       " 'plant': 513,\n",
       " 'plastic': 514,\n",
       " 'plate': 515,\n",
       " 'platform': 516,\n",
       " 'pleas': 517,\n",
       " 'pocket': 518,\n",
       " 'polit': 519,\n",
       " 'pollut': 520,\n",
       " 'pop': 521,\n",
       " 'popul': 522,\n",
       " 'posit': 523,\n",
       " 'possess': 524,\n",
       " 'possibl': 525,\n",
       " 'poster': 526,\n",
       " 'power': 527,\n",
       " 'predict': 528,\n",
       " 'present': 529,\n",
       " 'presid': 530,\n",
       " 'prevent': 531,\n",
       " 'print': 532,\n",
       " 'printer': 533,\n",
       " 'prison': 534,\n",
       " 'prize': 535,\n",
       " 'process': 536,\n",
       " 'produc': 537,\n",
       " 'profession': 538,\n",
       " 'professor': 539,\n",
       " 'profil': 540,\n",
       " 'progress': 541,\n",
       " 'promis': 542,\n",
       " 'pronounc': 543,\n",
       " 'protect': 544,\n",
       " 'provid': 545,\n",
       " 'public': 546,\n",
       " 'publish': 547,\n",
       " 'pull': 548,\n",
       " 'purpos': 549,\n",
       " 'push': 550,\n",
       " 'qualiti': 551,\n",
       " 'quantiti': 552,\n",
       " 'queen': 553,\n",
       " 'question': 554,\n",
       " 'quietli': 555,\n",
       " 'race': 556,\n",
       " 'railroad': 557,\n",
       " 'rais': 558,\n",
       " 'rate': 559,\n",
       " 'rather': 560,\n",
       " 'reach': 561,\n",
       " 'react': 562,\n",
       " 'realiz': 563,\n",
       " 'receiv': 564,\n",
       " 'recent': 565,\n",
       " 'recept': 566,\n",
       " 'recip': 567,\n",
       " 'recogn': 568,\n",
       " 'recommend': 569,\n",
       " 'record': 570,\n",
       " 'recycl': 571,\n",
       " 'reduc': 572,\n",
       " 'refer': 573,\n",
       " 'refriger': 574,\n",
       " 'refus': 575,\n",
       " 'region': 576,\n",
       " 'regular': 577,\n",
       " 'relationship': 578,\n",
       " 'remov': 579,\n",
       " 'repair': 580,\n",
       " 'replac': 581,\n",
       " 'repli': 582,\n",
       " 'report': 583,\n",
       " 'request': 584,\n",
       " 'research': 585,\n",
       " 'respond': 586,\n",
       " 'respons': 587,\n",
       " 'rest': 588,\n",
       " 'review': 589,\n",
       " 'ride': 590,\n",
       " 'ring': 591,\n",
       " 'rise': 592,\n",
       " 'rock': 593,\n",
       " 'role': 594,\n",
       " 'roof': 595,\n",
       " 'round': 596,\n",
       " 'rout': 597,\n",
       " 'rude': 598,\n",
       " 'run': 599,\n",
       " 'runner': 600,\n",
       " 'sadli': 601,\n",
       " 'safe': 602,\n",
       " 'sail': 603,\n",
       " 'salari': 604,\n",
       " 'sale': 605,\n",
       " 'sauc': 606,\n",
       " 'save': 607,\n",
       " 'scare': 608,\n",
       " 'scari': 609,\n",
       " 'scene': 610,\n",
       " 'schedul': 611,\n",
       " 'score': 612,\n",
       " 'screen': 613,\n",
       " 'sea': 614,\n",
       " 'search': 615,\n",
       " 'season': 616,\n",
       " 'seat': 617,\n",
       " 'second': 618,\n",
       " 'secret': 619,\n",
       " 'secretari': 620,\n",
       " 'seem': 621,\n",
       " 'sens': 622,\n",
       " 'separ': 623,\n",
       " 'seri': 624,\n",
       " 'seriou': 625,\n",
       " 'serv': 626,\n",
       " 'servic': 627,\n",
       " 'sever': 628,\n",
       " 'shake': 629,\n",
       " 'shape': 630,\n",
       " 'sheet': 631,\n",
       " 'ship': 632,\n",
       " 'shoulder': 633,\n",
       " 'shout': 634,\n",
       " 'shut': 635,\n",
       " 'side': 636,\n",
       " 'sign': 637,\n",
       " 'silver': 638,\n",
       " 'simpl': 639,\n",
       " 'sinc': 640,\n",
       " 'sing': 641,\n",
       " 'singl': 642,\n",
       " 'sir': 643,\n",
       " 'site': 644,\n",
       " 'size': 645,\n",
       " 'ski': 646,\n",
       " 'skin': 647,\n",
       " 'sky': 648,\n",
       " 'sleep': 649,\n",
       " 'slowli': 650,\n",
       " 'smartphon': 651,\n",
       " 'smell': 652,\n",
       " 'smile': 653,\n",
       " 'smoke': 654,\n",
       " 'sneaker': 655,\n",
       " 'soap': 656,\n",
       " 'soccer': 657,\n",
       " 'social': 658,\n",
       " 'societi': 659,\n",
       " 'sock': 660,\n",
       " 'soft': 661,\n",
       " 'soldier': 662,\n",
       " 'solut': 663,\n",
       " 'solv': 664,\n",
       " 'somewher': 665,\n",
       " 'sort': 666,\n",
       " 'sourc': 667,\n",
       " 'speaker': 668,\n",
       " 'specif': 669,\n",
       " 'speech': 670,\n",
       " 'speed': 671,\n",
       " 'spider': 672,\n",
       " 'spoon': 673,\n",
       " 'squar': 674,\n",
       " 'stage': 675,\n",
       " 'stair': 676,\n",
       " 'stamp': 677,\n",
       " 'star': 678,\n",
       " 'start': 679,\n",
       " 'state': 680,\n",
       " 'stay': 681,\n",
       " 'steal': 682,\n",
       " 'step': 683,\n",
       " 'stomach': 684,\n",
       " 'stone': 685,\n",
       " 'storm': 686,\n",
       " 'stove': 687,\n",
       " 'straight': 688,\n",
       " 'strang': 689,\n",
       " 'strategi': 690,\n",
       " 'stress': 691,\n",
       " 'structur': 692,\n",
       " 'stupid': 693,\n",
       " 'subway': 694,\n",
       " 'succeed': 695,\n",
       " 'success': 696,\n",
       " 'suddenli': 697,\n",
       " 'suggest': 698,\n",
       " 'suit': 699,\n",
       " 'support': 700,\n",
       " 'suppos': 701,\n",
       " 'sure': 702,\n",
       " 'surpris': 703,\n",
       " 'survey': 704,\n",
       " 'sweet': 705,\n",
       " 'symbol': 706,\n",
       " 'system': 707,\n",
       " 'tablet': 708,\n",
       " 'talk': 709,\n",
       " 'target': 710,\n",
       " 'task': 711,\n",
       " 'tast': 712,\n",
       " 'teach': 713,\n",
       " 'technolog': 714,\n",
       " 'teenag': 715,\n",
       " 'temperatur': 716,\n",
       " 'term': 717,\n",
       " 'text': 718,\n",
       " 'thick': 719,\n",
       " 'thief': 720,\n",
       " 'thin': 721,\n",
       " 'think': 722,\n",
       " 'third': 723,\n",
       " 'thought': 724,\n",
       " 'throw': 725,\n",
       " 'tie': 726,\n",
       " 'tip': 727,\n",
       " 'tool': 728,\n",
       " 'top': 729,\n",
       " 'touch': 730,\n",
       " 'tour': 731,\n",
       " 'tourism': 732,\n",
       " 'toward': 733,\n",
       " 'towel': 734,\n",
       " 'tower': 735,\n",
       " 'toy': 736,\n",
       " 'track': 737,\n",
       " 'tradit': 738,\n",
       " 'train': 739,\n",
       " 'transport': 740,\n",
       " 'trash': 741,\n",
       " 'travel': 742,\n",
       " 'troubl': 743,\n",
       " 'twin': 744,\n",
       " 'typic': 745,\n",
       " 'underground': 746,\n",
       " 'understand': 747,\n",
       " 'unfortun': 748,\n",
       " 'unhappi': 749,\n",
       " 'uniform': 750,\n",
       " 'unit': 751,\n",
       " 'unusu': 752,\n",
       " 'upstair': 753,\n",
       " 'use': 754,\n",
       " 'user': 755,\n",
       " 'usual': 756,\n",
       " 'valley': 757,\n",
       " 'varieti': 758,\n",
       " 'vehicl': 759,\n",
       " 'view': 760,\n",
       " 'villag': 761,\n",
       " 'viru': 762,\n",
       " 'voic': 763,\n",
       " 'wait': 764,\n",
       " 'war': 765,\n",
       " 'wash': 766,\n",
       " 'wave': 767,\n",
       " 'weak': 768,\n",
       " 'web': 769,\n",
       " 'wed': 770,\n",
       " 'weight': 771,\n",
       " 'welcom': 772,\n",
       " 'wet': 773,\n",
       " 'wheel': 774,\n",
       " 'whole': 775,\n",
       " 'whose': 776,\n",
       " 'wide': 777,\n",
       " 'wild': 778,\n",
       " 'wind': 779,\n",
       " 'winner': 780,\n",
       " 'wish': 781,\n",
       " 'wood': 782,\n",
       " 'wooden': 783,\n",
       " 'work': 784,\n",
       " 'worri': 785,\n",
       " 'wors': 786,\n",
       " 'worst': 787,\n",
       " 'wow': 788,\n",
       " 'yet': 789,\n",
       " 'zero': 790,\n",
       " 'b': 791,\n",
       " 'absolut': 792,\n",
       " 'academ': 793,\n",
       " 'access': 794,\n",
       " 'account': 795,\n",
       " 'ad': 796,\n",
       " 'addit': 797,\n",
       " 'administr': 798,\n",
       " 'admir': 799,\n",
       " 'admit': 800,\n",
       " 'advanc': 801,\n",
       " 'advis': 802,\n",
       " 'afford': 803,\n",
       " 'age': 804,\n",
       " 'agent': 805,\n",
       " 'agreement': 806,\n",
       " 'ahead': 807,\n",
       " 'aim': 808,\n",
       " 'alarm': 809,\n",
       " 'album': 810,\n",
       " 'alcohol': 811,\n",
       " 'amaz': 812,\n",
       " 'ambit': 813,\n",
       " 'analysi': 814,\n",
       " 'announc': 815,\n",
       " 'annoy': 816,\n",
       " 'apart': 817,\n",
       " 'apolog': 818,\n",
       " 'applic': 819,\n",
       " 'appoint': 820,\n",
       " 'appreci': 821,\n",
       " 'approxim': 822,\n",
       " 'arrest': 823,\n",
       " 'arriv': 824,\n",
       " 'assign': 825,\n",
       " 'atmospher': 826,\n",
       " 'attach': 827,\n",
       " 'attitud': 828,\n",
       " 'automat': 829,\n",
       " 'awar': 830,\n",
       " 'backward': 831,\n",
       " 'bake': 832,\n",
       " 'balanc': 833,\n",
       " 'ban': 834,\n",
       " 'bank': 835,\n",
       " 'basic': 836,\n",
       " 'basi': 837,\n",
       " 'batteri': 838,\n",
       " 'battl': 839,\n",
       " 'beauti': 840,\n",
       " 'bee': 841,\n",
       " 'belief': 842,\n",
       " 'bell': 843,\n",
       " 'bend': 844,\n",
       " 'bite': 845,\n",
       " 'bomb': 846,\n",
       " 'border': 847,\n",
       " 'bother': 848,\n",
       " 'branch': 849,\n",
       " 'brand': 850,\n",
       " 'brave': 851,\n",
       " 'breath': 852,\n",
       " 'bride': 853,\n",
       " 'bubbl': 854,\n",
       " 'buri': 855,\n",
       " 'cabl': 856,\n",
       " 'calm': 857,\n",
       " 'campaign': 858,\n",
       " 'candid': 859,\n",
       " 'cap': 860,\n",
       " 'captain': 861,\n",
       " 'careless': 862,\n",
       " 'categori': 863,\n",
       " 'ceil': 864,\n",
       " 'center': 865,\n",
       " 'central': 866,\n",
       " 'ceremoni': 867,\n",
       " 'chain': 868,\n",
       " 'challeng': 869,\n",
       " 'champion': 870,\n",
       " 'channel': 871,\n",
       " 'chapter': 872,\n",
       " 'charg': 873,\n",
       " 'cheap': 874,\n",
       " 'cheat': 875,\n",
       " 'cheer': 876,\n",
       " 'chemic': 877,\n",
       " 'chest': 878,\n",
       " 'childhood': 879,\n",
       " 'claim': 880,\n",
       " 'claus': 881,\n",
       " 'clever': 882,\n",
       " 'click': 883,\n",
       " 'client': 884,\n",
       " 'climb': 885,\n",
       " 'clue': 886,\n",
       " 'coal': 887,\n",
       " 'coin': 888,\n",
       " 'color': 889,\n",
       " 'combin': 890,\n",
       " 'commerci': 891,\n",
       " 'commit': 892,\n",
       " 'comparison': 893,\n",
       " 'competitor': 894,\n",
       " 'complaint': 895,\n",
       " 'complex': 896,\n",
       " 'concentr': 897,\n",
       " 'conclud': 898,\n",
       " 'conclus': 899,\n",
       " 'confid': 900,\n",
       " 'confirm': 901,\n",
       " 'confus': 902,\n",
       " 'consequ': 903,\n",
       " 'consist': 904,\n",
       " 'consum': 905,\n",
       " 'contact': 906,\n",
       " 'content': 907,\n",
       " 'contrast': 908,\n",
       " 'conveni': 909,\n",
       " 'convinc': 910,\n",
       " 'cool': 911,\n",
       " 'corn': 912,\n",
       " 'costum': 913,\n",
       " 'cotton': 914,\n",
       " 'countrysid': 915,\n",
       " 'court': 916,\n",
       " 'cream': 917,\n",
       " 'cruel': 918,\n",
       " 'cultur': 919,\n",
       " 'cupboard': 920,\n",
       " 'currenc': 921,\n",
       " 'current': 922,\n",
       " 'curtain': 923,\n",
       " 'custom': 924,\n",
       " 'cut': 925,\n",
       " 'damag': 926,\n",
       " 'decad': 927,\n",
       " 'defin': 928,\n",
       " 'deliv': 929,\n",
       " 'departur': 930,\n",
       " 'despit': 931,\n",
       " 'destin': 932,\n",
       " 'determin': 933,\n",
       " 'diagram': 934,\n",
       " 'diamond': 935,\n",
       " 'difficulti': 936,\n",
       " 'directli': 937,\n",
       " 'dirt': 938,\n",
       " 'disadvantag': 939,\n",
       " 'disappoint': 940,\n",
       " 'discount': 941,\n",
       " 'dislik': 942,\n",
       " 'district': 943,\n",
       " 'divid': 944,\n",
       " 'documentari': 945,\n",
       " 'donat': 946,\n",
       " 'doubl': 947,\n",
       " 'doubt': 948,\n",
       " 'dress': 949,\n",
       " 'drum': 950,\n",
       " 'drunk': 951,\n",
       " 'due': 952,\n",
       " 'dust': 953,\n",
       " 'duti': 954,\n",
       " 'earthquak': 955,\n",
       " 'eastern': 956,\n",
       " 'econom': 957,\n",
       " 'economi': 958,\n",
       " 'edg': 959,\n",
       " 'editor': 960,\n",
       " 'effort': 961,\n",
       " 'elect': 962,\n",
       " 'element': 963,\n",
       " 'embarrass': 964,\n",
       " 'emerg': 965,\n",
       " 'emot': 966,\n",
       " 'encourag': 967,\n",
       " 'enemi': 968,\n",
       " 'engag': 969,\n",
       " 'entertain': 970,\n",
       " 'entranc': 971,\n",
       " 'entri': 972,\n",
       " 'environment': 973,\n",
       " 'episod': 974,\n",
       " 'equal': 975,\n",
       " 'escap': 976,\n",
       " 'essenti': 977,\n",
       " 'eventu': 978,\n",
       " 'examin': 979,\n",
       " 'exchang': 980,\n",
       " 'excit': 981,\n",
       " 'exhibit': 982,\n",
       " 'exit': 983,\n",
       " 'expand': 984,\n",
       " 'experienc': 985,\n",
       " 'explod': 986,\n",
       " 'explor': 987,\n",
       " 'explos': 988,\n",
       " 'export': 989,\n",
       " 'extra': 990,\n",
       " 'face': 991,\n",
       " 'fairli': 992,\n",
       " 'familiar': 993,\n",
       " 'fanci': 994,\n",
       " 'far': 995,\n",
       " 'fascin': 996,\n",
       " 'fasten': 997,\n",
       " 'favor': 998,\n",
       " 'feder': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_voc = np.array(dict_eng['words'])\n",
    "ind_voc = [i for i in range(len(dict_eng))]\n",
    "eng_vocabulary = dict(zip(eng_voc, ind_voc))\n",
    "eng_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd1bf5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"pickle_dict.pkl\" \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(eng_vocabulary, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b48b53",
   "metadata": {},
   "source": [
    "Этот словарь передам модели в приложение.\n",
    "\n",
    "Может быть так, что в предыдущих обработках какие-то слова испортились или в тексте встречаются опечатки, поэтому в качестве параметра векторизации возьму минимальное число документов, в которых встречается слово, - два."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f08635a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(min_df=2, vocabulary=eng_vocabulary) \n",
    "\n",
    "bag = count.fit_transform(df['Srt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6cdd675",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "bag = tfidfconverter.fit_transform(bag).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ccd6bc",
   "metadata": {},
   "source": [
    "Преобразование из слов в цифры закончилось. Теперь эту матрицу надо соотнести с таргетом и построить на их основе модель предсказания.\n",
    "\n",
    "### Построение модели\n",
    "\n",
    "#### Обучающая и тестовая выборки\n",
    "\n",
    "Я собираюсь использовать кросс-валидацию, поэтому валидационная выборка  не нужна, только тестовая и обучающая.\n",
    "\n",
    "Разделю в соотношении 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d718cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = bag\n",
    "target = df['Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aff1cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.3, random_state=RANDOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f268d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1','l2'],               \n",
    "              'solver': ['lbfgs', 'newton-cg'],              \n",
    "              'C': [1.0, 10.0, 100.0]}\n",
    "              \n",
    "\n",
    "model = LogisticRegression(random_state=RANDOM, n_jobs=1, multi_class='auto')\n",
    "\n",
    "gs= GridSearchCV(model, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "11218f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(n_jobs=1, random_state=123),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [1.0, 10.0, 100.0], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(n_jobs=1, random_state=123),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [1.0, 10.0, 100.0], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;newton-cg&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=1, random_state=123)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=1, random_state=123)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(n_jobs=1, random_state=123),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'C': [1.0, 10.0, 100.0], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['lbfgs', 'newton-cg']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d5b9aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'} \n",
      "CV Accuracy: 0.649\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter set: %s ' % gs.best_params_)\n",
    "print('CV Accuracy: %.3f' % gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37c335ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.695\n"
     ]
    }
   ],
   "source": [
    "best_model = gs.best_estimator_\n",
    "print('Test Accuracy: %.3f' % best_model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "79e71da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Level_target</th>\n",
       "      <th>Level_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>204</td>\n",
       "      <td>C1</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>258</td>\n",
       "      <td>B2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>36</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>194</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>242</td>\n",
       "      <td>B2</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>95</td>\n",
       "      <td>B2</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52</td>\n",
       "      <td>B1</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index Level_target Level_pred\n",
       "20    204           C1         C1\n",
       "37    258           B2         B1\n",
       "52     36           B2         B2\n",
       "0     167           B2         B2\n",
       "67    194           B2         B2\n",
       "64    242           B2         B2\n",
       "44     95           B2         B1\n",
       "10     52           B1         B1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = best_model.predict(features_test)\n",
    "df_test = pd.DataFrame()\n",
    "df_test['Level_target'] = target_test\n",
    "df_test = df_test.reset_index()\n",
    "df_test['Level_pred'] = pd.Series(predicted)\n",
    "df_test.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5443b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B2', 'B1', 'C1', 'A2'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Level_pred'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb927d0d",
   "metadata": {},
   "source": [
    "Можем увидеть, что модель худо-бедно предсказывает уровень сложности текста.\n",
    "\n",
    "Теперь выложу её в отдельный файл, чтоб использовать в приложении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32bc4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"pickle_model.pkl\" \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab81b9",
   "metadata": {},
   "source": [
    "###  Итог\n",
    "\n",
    "В тетради я объединила три таблицы субтитров, отредактировала текст, убрав ненужные символы, цифры, пробелы, оставила только грамматические основы. Создала словарь для векторизации любого входящего текста, не только обучающего модель. Построила на частотности появления основ в документе и во всём объёме текстов векторы для модели, опираясь на словарь. Обучила модель линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3dfe2334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'} \n",
      "Test Accuracy: 0.695\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter set: %s ' % gs.best_params_)\n",
    "print('Test Accuracy: %.3f' % best_model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac7a36",
   "metadata": {},
   "source": [
    "Словарь и модель записала в отдельные файлы для предоставления их в приложение. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ada9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d16fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d39ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420534c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0c976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
